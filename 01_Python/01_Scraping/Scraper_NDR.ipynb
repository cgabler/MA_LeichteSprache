{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ff9bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "URL = \"https://www.ndr.de/fernsehen/barrierefreie_angebote/leichte_sprache/Alle-Nachrichten-in-Leichter-Sprache,leichtesprachearchiv110.html\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_single = []\n",
    "articles_collection = []\n",
    "\n",
    "for i in range(1, 240):\n",
    "    url = \"https://www.ndr.de/fernsehen/barrierefreie_angebote/leichte_sprache/leichtesprachearchiv110_page-%s.html\" % (i)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    print(url)\n",
    "    headlines = soup.find_all(\"h2\")\n",
    "    for headline in headlines:\n",
    "        #print(headline.prettify(), end=\"\\n\"*2)\n",
    "        links = headline.find_all(\"a\")  \n",
    "        for link in links:\n",
    "            if \"Mehr-Nachrichten-vom\" in link[\"href\"]:\n",
    "                articles_collection.append(link[\"href\"])\n",
    "            else:\n",
    "                articles_single.append(link[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['URL', 'Titel', 'Text_Leicht'])\n",
    "i = 1\n",
    "\n",
    "for article in articles_collection:\n",
    "    url = 'https://www.ndr.de%s' % (article)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    end_of_article = False\n",
    "    for heading in soup.find_all(\"h2\"):  # find separators, in this case h2 nodes\n",
    "        article_text = ''\n",
    "        for sibling in heading.find_next_siblings():\n",
    "            if sibling.name == \"h2\":  # iterate through siblings until separator is encoutnered\n",
    "                break\n",
    "            t = sibling.getText()\n",
    "            if \"Diese Nachrichten sind vom\" in t:\n",
    "                end_of_article = True\n",
    "                break\n",
    "            else:\n",
    "                clean_text = unicodedata.normalize(\"NFKD\",t)\n",
    "                if \"-------------------------------------------------------------------\" not in clean_text:\n",
    "                    article_text = article_text + (' '.join(clean_text.split()))\n",
    "        \n",
    "        df_article = pd.DataFrame({\n",
    "            'URL': url,\n",
    "            'Titel': heading.text,\n",
    "            'Text_Leicht': article_text},\n",
    "            index=[i]\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        df = pd.concat([df, df_article])\n",
    "\n",
    "        if end_of_article:\n",
    "            break\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "242a2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ndr_article_collection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabc82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['URL', 'Titel', 'Text_Leicht'])\n",
    "i = 1\n",
    "for article in articles_single:\n",
    "    url = 'https://www.ndr.de%s' % (article)\n",
    "\n",
    "    if url != 'https://www.ndr.de/fernsehen/barrierefreie_angebote/index.html':\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        article_title = ''\n",
    "        article_text = ''\n",
    "        for heading in soup.find_all(\"h1\"):\n",
    "            article_title = unicodedata.normalize(\"NFKD\",heading.getText()).replace('\\n', '')\n",
    "            break\n",
    "\n",
    "        for p in soup.find_all(\"p\"):\n",
    "            clean_text = unicodedata.normalize(\"NFKD\",p.getText())\n",
    "            if \"Diese Nachricht ist vom \" in clean_text:\n",
    "                break\n",
    "            article_text = article_text + ' '+ (' '.join(clean_text.split()))\n",
    "\n",
    "        df_article = pd.DataFrame({\n",
    "            'URL': url,\n",
    "            'Titel': article_title,\n",
    "            'Text_Leicht': article_text},\n",
    "            index=[i]\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        df = pd.concat([df, df_article])\n",
    "\n",
    "        print(url)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ad0d06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ndr_article_single.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0fbf8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Niedersachsen: Autobahn 7 gesperrt': ['Am Donnerstag hat die Polizei einen Teil von der A7 gesperrt.', 'A7 ist die Abkürzung für Autobahn 7.', 'Dieser Teil ist in der Nähe von Salzgitter.', 'Salzgitter ist eine Stadt südlich von Braunschweig.', 'Die Polizei hat gesagt:', 'Auf der A7 war ein Unfall.', 'Bei dem Unfall wurde kein Mensch verletzt.', 'Aber bei dem Unfall ist ein Lkw umgekippt.', 'Jetzt liegt der Lkw auf der A7.', 'Und er blockiert alle Fahr·spuren in Richtung Norden.', 'Deshalb haben wir den Teil von der A7 gesperrt.', 'Und deshalb ist ein langer Stau.', 'Die Polizei hat auch gesagt:', 'Jetzt müssen Fach·leute den Lkw von der A7 holen.', 'Das dauert noch einige Stunden.', 'Deshalb bleibt der Teil von der A7 wahrscheinlich noch einige Stunden gesperrt.', 'Noch weiß kein Mensch:', 'Warum ist der Lkw umgekippt?'], 'Niedersachsen: Mann stirbt bei Unfall': ['Am Donnerstag·morgen war ein Unfall.', 'Der Unfall war in Samern.', 'Samern ist ein Ort im Süd·westen von Niedersachsen.', 'Bei dem Unfall ist ein Mann gestorben.', 'Die Polizei hat gesagt:', 'Der Mann ist mit seinem Auto in eine Kurve gefahren.', 'Dann ist er auf die Gegen·fahr·bahn gekommen.', 'Auf der Gegen·fahr·bahn ist eine Frau mit ihrem Auto gefahren.', 'Die 2 Autos sind zusammengestoßen.', 'Der Mann ist gestorben.', 'Und die Frau wurde schwer verletzt.', 'Noch weiß kein Mensch:', 'Warum ist der Mann auf die Gegen·fahr·bahn gekommen?']}\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "blocks = {}\n",
    "end_of_article = False\n",
    "for heading in soup.find_all(\"h2\"):  # find separators, in this case h2 nodes\n",
    "    values = []\n",
    "    for sibling in heading.find_next_siblings():\n",
    "        if sibling.name == \"h2\":  # iterate through siblings until separator is encoutnered\n",
    "            break\n",
    "        t = sibling.getText()\n",
    "        if \"Diese Nachrichten sind vom\" in t:\n",
    "            end_of_article = True\n",
    "            break\n",
    "        else:\n",
    "            clean_text = unicodedata.normalize(\"NFKD\",t)\n",
    "            if \"-------------------------------------------------------------------\" not in clean_text:\n",
    "                values.append(' '.join(clean_text.split()))\n",
    "    blocks[heading.text] = values\n",
    "    if end_of_article:\n",
    "        break\n",
    "\n",
    "        \n",
    "print(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = soup.find_all(\"h2\")\n",
    "for headline in headlines:\n",
    "    #print(headline.prettify(), end=\"\\n\"*2)\n",
    "    links = headline.find_all(\"a\")  \n",
    "    for link in links:\n",
    "        print(link.prettify())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83f666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2 class=\"SP-Headline--section\" id=\"abschriften-urkunden-ausweise-paesse\">\n",
      " Abschriften &amp; Urkunden, Ausweise &amp; Pässe\n",
      "</h2>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = soup.find(id=\"abschriften-urkunden-ausweise-paesse\")\n",
    "print(result.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_elements = soup.find_all(\"section\", class_=\"SP-Section\")\n",
    "\n",
    "for category_element in category_elements:\n",
    "    print(category_element.prettify(), end=\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "895c800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://stuttgart.de/organigramm/leistungen/personalausweis-beantragen-erstmalig-oder-nach-ablauf.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/personalausweis-wegen-namenaenderung-beantragen-heirat-oder-scheidung-.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/reisepass-beantragen-erstmalig-oder-nach-ablauf.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/reisepass-beantragen-vorlaeufig.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/schwerbehinderten-ausweis-beantragen.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/urkunden-und-beglaubigte-abschriften-geburt-heirat-lebens-partnerschaft-und-sterbefall.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/die-beauftragte-fuer-menschen-mit-behinderung.php?sp%3Aout=easy', 'https://stuttgart.de/service/behoerdennummer-115/index.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/politik-von-menschen-mit-behinderung/beirat-inklusion.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/beratungsangebote-fuer-menschen-mit-behinderung/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/arbeit/arbeitsuchende/hilfe-beim-wiedereinstieg.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/die-beauftragte-fuer-menschen-mit-behinderung/inklusion-teilhabe.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/politik-von-menschen-mit-behinderung/index.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/menschen-mit-behinderung/wege-in-die-arbeit/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/beratung-und-hilfe/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/arbeit/buergergeld/index.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/eingliederungshilfe-fuer-menschen-mit-behinderung.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/gemeinsam-gegen-einsamkeit/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/beratung-und-hilfe/gesetzliche-betreuung.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/gesundheitsberatung/index.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/chancengleichheit/haeusliche-gewalt/gewalt-in-haeuslicher-pflege.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/chancengleichheit/haeusliche-gewalt/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/vorsorge/impfungen.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/infektionsschutz/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/soziale-leistungen/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/sozialplanung/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/vorsorge/suchtpraevention.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/umweltmedizin/index.php?sp%3Aout=easy', 'https://stuttgart.de/leben/gesundheit/vorsorge/index.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/ehefaehigkeitszeugnis-ehe-faehigkeits-zeugnis-ausstellung-beantragen.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/ehenamen-bestimmen.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/heiraten/eheschliessung.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/eheschliessung-anmelden.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/lebens-partnerschaft-umwandlung-in-eine-ehe-beantragen.php?sp%3Aout=easy', 'https://stuttgart.de/leben/sport/sportprogramme/bewegt-und-aktiv.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/senioren/beratung-und-angebote.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/senioren/buergerservice-leben-im-alter.php?sp%3Aout=easy', 'https://stuttgart.de/buergerinnen-und-buerger/senioren/gesund-aelter-werden.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/senioren-jahresticket-beantragen-bei-rueckgabe-des-fuehrerscheins.php?sp%3Aout=easy', 'https://stuttgart.de/leben/soziales/generationenhaus.php?sp%3Aout=easy', 'https://stuttgart.de/leben/wohnen/foerderung-und-wohnungshilfe/seniorenmietwohnungen.php?sp%3Aout=easy', 'https://stuttgart.de/leben/wohnen/foerderung-und-wohnungshilfe/sozialmietwohnungen.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/wohnberechtigungsschein-beantragen.php?sp%3Aout=easy', 'https://stuttgart.de?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/wohnsitz-anmelden-als-hauptwohnsitz.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/wohnsitz-anmelden-durch-wohnungsgeber-bescheinigung-vom-wohnungs-geber-.php?sp%3Aout=easy', 'https://stuttgart.de/organigramm/leistungen/wohnsitz-ummelden-innerhalb-von-stuttgart.php?sp%3Aout=easy']\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "easyLink = \"?sp%3Aout=easy\"\n",
    "for category_element in category_elements:\n",
    "    link_elements = category_element.find_all(\"a\", class_=\"SP-Link SP-Iconized--left\")\n",
    "    for link_element in link_elements:\n",
    "        if easyLink in link_element[\"href\"]:\n",
    "            links.append(\"https://stuttgart.de\"+link_element[\"href\"])\n",
    "        \n",
    "        \n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e47c7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['URL', 'Titel', 'Text_Leicht', 'Text_Allgemein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd45703",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for url in links:\n",
    "    try:\n",
    "        url2 = url.replace(\"?sp%3Aout=easy\", \"\")\n",
    "        page = requests.get(url)\n",
    "        page2 = requests.get(url2)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        soup2 = BeautifulSoup(page2.content, \"html.parser\")\n",
    "\n",
    "        result = soup.find(\"h1\", class_=\"SP-Headline--article\")\n",
    "        title = result.text\n",
    "\n",
    "        print(title, url)\n",
    "\n",
    "        result = soup.find(\"div\", class_=\"SP-ArticleContent\")\n",
    "        for div in result.find_all(\"section\", class_=\"SP-Text\"):\n",
    "            for h2 in div.find_all(\"h2\", id=\"kontakt\"):\n",
    "                div.decompose()\n",
    "\n",
    "        text = result.getText(separator=u' ')\n",
    "\n",
    "        result2 = soup2.find(\"div\", class_=\"SP-ArticleContent\")\n",
    "\n",
    "        for div in result2.find_all(\"section\", class_=\"SP-Section SP-Grid__full\"):\n",
    "            for h2 in div.find_all(\"h2\"):\n",
    "                if(h2.text == 'Ihr Kontakt zu uns:'):\n",
    "                    div.decompose()\n",
    "\n",
    "        for div in result2.find_all(\"section\", class_=\"SP-Text\"):\n",
    "            for h2 in div.find_all(\"h2\", id=\"service-telefon\"):\n",
    "                div.decompose()    \n",
    "\n",
    "        text2 = result2.getText(separator=u' ')    \n",
    "\n",
    "        df_article = pd.DataFrame({\n",
    "            'URL': url,\n",
    "            'Titel': title,\n",
    "            'Text_Leicht': text,\n",
    "            'Text_Allgemein': text2},\n",
    "            index=[i]\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        df = pd.concat([df, df_article])\n",
    "    except:\n",
    "        print(\"Error with \", title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "569c1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../02_Data/ndr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41001816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
