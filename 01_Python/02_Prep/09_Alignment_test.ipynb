{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matching.utilities as utl\n",
    "\n",
    "from defaultvalues import *\n",
    "\n",
    "def main():\n",
    "    \"\"\" This function generates all alignments according to sepcific parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for generation\n",
    "    sim_measure = \"maximum\"\n",
    "    sd_threshold = 1.5\n",
    "    doc_matching = \"max_increasing_subsequence\"\n",
    "\n",
    "    # setup\n",
    "    pairs = utl.get_article_pairs()\n",
    "    #if not os.path.isdir(f\"{results_location}/alignment\"):\n",
    "        #os.makedirs(f\"{results_location}/alignment\")\n",
    "    if not os.path.isdir(\"../02_Data/alignment\"):\n",
    "        os.makedirs(\"../02_Data/alignment\")\n",
    "\n",
    "    alignment = {}\n",
    "    for matching_simple, matching_normal in tqdm(pairs):\n",
    "        # get filenames and get the path to the matching calculated by old_main_matching.py\n",
    "        simple_file = matching_simple.split(\"/\")[-1]\n",
    "        normal_file = matching_normal.split(\"/\")[-1]\n",
    "        name = utl.make_matching_path(\n",
    "            simple_file, normal_file, sim_measure, doc_matching, sd_threshold)\n",
    "\n",
    "        easy_lines = []\n",
    "        normal_lines = []\n",
    "        with open(name, encoding=\"utf-8\") as fp:\n",
    "            matches = json.load(fp)\n",
    "            for match in matches:\n",
    "                # read information of the matches\n",
    "                i_normal = match[0][1]  # index of the normal sentence\n",
    "                sentence_pair = match[1]\n",
    "                distance = match[2]\n",
    "\n",
    "                easy_lines.append(sentence_pair[0])\n",
    "                normal_lines.append(sentence_pair[1])\n",
    "                # add the alignment to logging\n",
    "                if not normal_file in alignment:\n",
    "                    # first alignment of the normal filee\n",
    "                    alignment[normal_file] = {\n",
    "                        i_normal: [{\"sent\": sentence_pair, \"dist\": distance}]\n",
    "                    }\n",
    "                elif not i_normal in alignment[normal_file]:\n",
    "                    # first time the specific index was used\n",
    "                    alignment[normal_file][i_normal] = [\n",
    "                        {\"sent\": sentence_pair, \"dist\": distance}]\n",
    "                else:\n",
    "                    # both the normal file and the index were logged before\n",
    "                    alignment[normal_file][i_normal].append(\n",
    "                        {\"sent\": sentence_pair, \"dist\": distance})\n",
    "        align_simple, align_normal = utl.make_alignment_path(\n",
    "            simple_file, normal_file)\n",
    "        with open(align_simple, \"w\", encoding=\"utf-8\") as fp_simple, open(align_normal, \"w\", encoding=\"utf-8\") as fp_normal:\n",
    "            fp_simple.write(\"\\n\".join(easy_lines))\n",
    "            fp_normal.write(\"\\n\".join(normal_lines))\n",
    "\n",
    "    # save all logged alignments for comprehensibility reasons\n",
    "    with open(\"../02_Data/alignment/alignments_with_distance.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dump(alignment, fp, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
